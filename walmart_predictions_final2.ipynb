{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import fbprophet as fb\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_cols_dict= {\n",
    "                'item':{'key':['id'],\n",
    "\t\t\t\t\t\t'incols':['id','item_id','dept_id','cat_id'],\n",
    "\t\t\t\t\t\t'outcols':['id','item_id','dept_id','cat_id']\n",
    "\t\t\t\t\t\t},\n",
    "               'store':{'key':['store_id'],\n",
    "\t\t\t            'incols':['store_id','state_id'],\n",
    "\t\t\t\t\t\t'outcols': ['store_id','state_id'] \n",
    "\t\t\t\t\t\t}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dimension(file_name,dim_cols_dict,dim_type):\n",
    "    dim_name = 'dim_' + dim_type\n",
    "    dim_key_cols = dim_cols_dict[dim_type]['key']\n",
    "    dim_in_all_cols = dim_cols_dict[dim_type]['incols']\n",
    "    dim_out_cols = dim_cols_dict[dim_type]['outcols']  \n",
    "    file_path = r'C:\\Users\\Rohan\\Desktop\\Kaggle\\M5_Walmart\\\\'\n",
    "    #file_name = 'sales_train_validation.csv'\n",
    "    dim_sk = dim_type + '_sk'\n",
    "    dim_max_sk_csv = dim_name + '_max_sk.csv'\n",
    "    dim_idx_lkp_csv = dim_name + '_idx_lkp.csv'\n",
    "    dim_csv = dim_name + '.csv'\n",
    "    dim_hash = dim_type + '_hash_key'\n",
    "    dim_out_all_cols = list(dim_out_cols)\n",
    "    dim_idx_cols = list(dim_key_cols)\n",
    "    dim_out_all_cols.extend([dim_sk,dim_hash,'rec_hash'])\n",
    "    dim_idx_cols.append(dim_sk)\n",
    "  \n",
    "    df1 = pd.read_csv(file_path + file_name )\n",
    "    df1 = df1[dim_in_all_cols]\n",
    "    df1.drop_duplicates(inplace=True)\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    try:\n",
    "        df_max_lkp = pd.read_csv(file_path + dim_max_sk_csv)\n",
    "        max_sk = df_max_lkp.iat[0,0]\n",
    "    except:\n",
    "        max_sk = 1\n",
    "    try:\n",
    "        df_dim_idx_lkp = pd.read_csv(file_path + dim_idx_lkp_csv,index_col=dim_hash)\n",
    "    except:\n",
    "        df_dim_idx_lkp = pd.DataFrame()\n",
    "  \n",
    "   \n",
    "    def lookup_fun(x):\n",
    "        try:\n",
    "            return(df_dim_idx_lkp.at[x,dim_sk])\n",
    "        except:\n",
    "            return(-1)\n",
    "    df1[dim_hash] = pd.util.hash_pandas_object(df1[dim_key_cols],index=False)\n",
    "    df1['rec_hash'] = pd.util.hash_pandas_object(df1[dim_out_cols],index=False)\n",
    "    df1[dim_sk] = df1[dim_hash].apply(lambda x: lookup_fun(x))\n",
    "    df1_dim_updates = df1[df1[dim_sk] != -1]\n",
    "    df1_dim_updates.reset_index(drop=True,inplace=True)\n",
    "    df1_dim_inserts = df1[df1[dim_sk] == -1]\n",
    "    if len(df1_dim_inserts) > 0:\n",
    "        df1_dim_inserts.reset_index(drop=True,inplace=True)\n",
    "        df1_dim_inserts[dim_sk] = df1_dim_inserts.index + max_sk\n",
    "        max_sk = df1_dim_inserts[dim_sk].max() + 1\n",
    "        if max_sk == max_sk:\n",
    "            pd.DataFrame.from_dict({'max_sk':[max_sk]}).to_csv(file_path + dim_max_sk_csv,index=None)\n",
    "            df1_dim_inserts.set_index(dim_hash,inplace=True)\n",
    "            df_dim_idx_lkp = df_dim_idx_lkp.append(df1_dim_inserts[dim_idx_cols])\n",
    "            df_dim_idx_lkp.to_csv(file_path + dim_idx_lkp_csv,header=True,index=True)\n",
    "            df1_dim_inserts.reset_index(inplace=True)\n",
    "        try:\n",
    "            df1_dim_current = pd.read_csv(file_path + dim_csv)\n",
    "        except:\n",
    "            df1_dim_current = pd.DataFrame(columns=dim_out_all_cols)\n",
    "        if len(df1_dim_updates) > 0:\n",
    "            df1_dim_updates['check_dup_up'] = df1_dim_updates['rec_hash'].isin(df1_dim_current['rec_hash'])\n",
    "            df1_dim_updates = df1_dim_updates[df1_dim_updates.check_dup_up == False]\n",
    "            df1_dim_current['check_up'] = df1_dim_current['rec_hash'].isin(df1_dim_updates['rec_hash'])\n",
    "            df1_dim_current = df1_dim_current[df1_dim_current.check_up == False]\n",
    "            df1_dim_current = df1_dim_current[dim_out_all_cols].append(df1_dim_updates[dim_out_all_cols])\n",
    "        df1_dim_current = df1_dim_current[dim_out_all_cols].append(df1_dim_inserts[dim_out_all_cols])\n",
    "        df1_dim_current.to_csv(file_path + dim_csv ,header=True,index=None)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sales_train_evaluation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dimension(file_name,dim_cols_dict,'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dim_for_fact(dim_cols_dict,dim_type):\n",
    "  dim_name = 'dim_' + dim_type\n",
    "  dim_key_cols = dim_cols_dict[dim_type]['key']\n",
    "  dim_in_all_cols = dim_cols_dict[dim_type]['incols']\n",
    "  dim_out_cols = dim_cols_dict[dim_type]['outcols']  \n",
    "  file_path = r'C:\\Users\\Rohan\\Desktop\\Kaggle\\M5_Walmart\\\\'\n",
    "  #file_name = 'sales_train_validation.csv'\n",
    "  dim_sk = dim_type + '_sk'\n",
    "  dim_max_sk_csv = dim_name + '_max_sk.csv'\n",
    "  dim_idx_lkp_csv = dim_name + '_idx_lkp.csv'\n",
    "  dim_csv = dim_name + '.csv'\n",
    "  dim_hash = dim_type + '_hash_key'\n",
    "  dim_out_all_cols = list(dim_out_cols)\n",
    "  dim_idx_cols = list(dim_key_cols)\n",
    "  dim_out_all_cols.extend([dim_sk,dim_hash,'rec_hash'])\n",
    "  dim_idx_cols.append(dim_sk)\n",
    "  df_dim_idx_lkp = pd.read_csv(file_path + dim_idx_lkp_csv,index_col=dim_hash)\n",
    "  return(df_dim_idx_lkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sk_to_fact(df_fact,dim_cols_dict,dim_type):\n",
    "  dim_hash = dim_type + '_hash_key'\n",
    "  dim_key_cols = dim_cols_dict[dim_type]['key']\n",
    "  dim_in_all_cols = dim_cols_dict[dim_type]['incols']\n",
    "  dim_in_all_cols.append(dim_hash)\n",
    "  dim_sk = dim_type + '_sk'\n",
    "  if dim_sk not in df_fact.columns:\n",
    "    df_fact[dim_hash] = pd.util.hash_pandas_object(df_fact[dim_key_cols],index=False)\n",
    "    df_dim_idx_lkp = read_dim_for_fact(dim_cols_dict,dim_type)\n",
    "    def lookup_fun(x):\n",
    "      try:\n",
    "        return(df_dim_idx_lkp.at[x,dim_sk])\n",
    "      except:\n",
    "        return(-1)\n",
    "    df_fact.insert(1,dim_sk,df_fact[dim_hash].apply(lambda x:lookup_fun(x)))\n",
    "    #df_fact[dim_sk] = df_fact[dim_hash].apply(lambda x:lookup_fun(x))\n",
    "    df_dim_placeholder = df_fact[dim_key_cols][df_fact[dim_sk] == -1]\n",
    "    df_fact.drop(columns=dim_in_all_cols,inplace=True)\n",
    "    return(df_fact,df_dim_placeholder)\n",
    "  else:\n",
    "    return(df_fact,pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\Rohan\\\\Desktop\\\\Kaggle\\\\M5_Walmart\\\\'\n",
    "in_file = 'sales_train_evaluation_10_items.csv'\n",
    "normalized_file = 'sales_train_evaluation_normalized_test4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_fact_input = pd.read_csv(file_path + in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_fact_input,df_item_placeholder = add_sk_to_fact(read_fact_input,dim_cols_dict,'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_sk</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_sk state_id  d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  ...  d_1932  \\\n",
       "0        1       CA    0    0    0    0    0    0    0    0  ...       2   \n",
       "1        2       CA    0    0    0    0    0    0    0    0  ...       0   \n",
       "2        3       CA    0    0    0    0    0    0    0    0  ...       1   \n",
       "3        4       CA    0    0    0    0    0    0    0    0  ...       1   \n",
       "4        5       CA    0    0    0    0    0    0    0    0  ...       0   \n",
       "\n",
       "   d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       4       0       0       0       0       3       3       0       1  \n",
       "1       1       2       1       1       0       0       0       0       0  \n",
       "2       0       2       0       0       0       2       3       0       1  \n",
       "3       1       0       4       0       1       3       0       2       6  \n",
       "4       0       0       2       1       0       0       2       1       0  \n",
       "\n",
       "[5 rows x 1943 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_fact_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_fact_input.drop(columns=['store_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_fact_input.to_csv(file_path + 'sales_evaluate_mapped_sk.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file2 = 'sales_evaluate_mapped_sk.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time is 2020-06-24 07:48:49.743428\n",
      "end time is 2020-06-24 07:48:49.823406\n"
     ]
    }
   ],
   "source": [
    "file_open = open(file_path + in_file2)\n",
    "file_contents = csv.reader(file_open)\n",
    "file_write = open(file_path + normalized_file,'a',newline='')\n",
    "print(F\"start time is {dt.now()}\")\n",
    "dim_fields = 2\n",
    "transaction_id = 1\n",
    "for i,row in enumerate(file_contents):\n",
    "    start = 2\n",
    "    if i == 0:\n",
    "        top_row = row\n",
    "        normalize = row[:dim_fields]\n",
    "        normalize.extend(['date','unit_sold','trasaction_id'])\n",
    "        row1 = normalize\n",
    "        row1_final = [row1[0]]\n",
    "        row1_final.extend(row1[-4:-1])\n",
    "        row_write = csv.writer(file_write)\n",
    "        row_write.writerow(row1_final)\n",
    "        nu_of_fields = len(top_row) - dim_fields\n",
    "    else:\n",
    "        start = dim_fields\n",
    "        for j in range(1,nu_of_fields+1):\n",
    "            normalize_data = row[:dim_fields]\n",
    "            #print(j,nu_of_fields,start)\n",
    "            date = top_row[start]\n",
    "            #print(date)\n",
    "            next_trans = row[start]\n",
    "            normalize_data.extend([date,next_trans,transaction_id])\n",
    "            #print(normalize_data)\n",
    "            transaction_id = transaction_id + 1\n",
    "            start = start + 1\n",
    "            row2 = normalize_data\n",
    "            #print(row2)\n",
    "            row2_final = [row2[0]]\n",
    "            row2_final.extend(row2[-4:-1])\n",
    "            row_write.writerow(row2_final)\n",
    "file_write.close()\n",
    "print(F\"end time is {dt.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.read_csv(file_path + 'calendar.csv',parse_dates=[0])\n",
    "df_calendar[['unwanted','date_sk']] = df_calendar.date_key.str.split(\"_\",expand=True)\n",
    "df_calendar.drop(columns=['unwanted'],inplace=True)\n",
    "df_calendar.year = df_calendar.year.astype('int64')\n",
    "df_calendar.date_sk = df_calendar.date_sk.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_full_file = pd.read_csv(file_path + normalized_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_sk</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>unit_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_sk state_id date  unit_sold\n",
       "0        1       CA  d_1          0\n",
       "1        1       CA  d_2          0\n",
       "2        1       CA  d_3          0\n",
       "3        1       CA  d_4          0\n",
       "4        1       CA  d_5          0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_full_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_id = df_read_full_file[['item_sk','state_id']][df_read_full_file.duplicated(subset=['item_sk','state_id']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_id.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_holiday(df_cal,state):      \n",
    "        if state == 'CA':\n",
    "            df_holiday = df_cal[(df_cal.event_name_1.notna()) | (df_cal.snap_CA == 1)]\n",
    "        elif state == 'TX':\n",
    "            df_holiday = df_cal[(df_cal.event_name_1.notna()) | (df_cal.snap_TX == 1)]\n",
    "        else:\n",
    "            df_holiday = df_cal[(df_cal.event_name_1.notna()) | (df_cal.snap_WI == 1)]\n",
    "        df_holiday['holiday'] = np.where(df_holiday.event_name_1.isna(),'snap',df_holiday.event_name_1)\n",
    "        df_holiday.rename(columns={'date':'ds'},inplace=True)\n",
    "        return(df_holiday[['holiday','ds']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for i in df_calendar.columns:\n",
    "    if 'snap' in i.lower():\n",
    "        states.append(i.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Rohan\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:4133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "holiday_ca = create_holiday(df_calendar,states[0])\n",
    "holiday_tx = create_holiday(df_calendar,states[1])\n",
    "holiday_wi = create_holiday(df_calendar,states[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calendar_lookup(x):\n",
    "    return(df_calendar.at[x,'date_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop start time 20200624 07:53:21\n",
      "1\n",
      "using cali holiday calendar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\Rohan\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\Rohan\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop end time 20200624 07:53:27\n",
      "loop start time 20200624 07:53:27\n",
      "2\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:53:33\n",
      "loop start time 20200624 07:53:33\n",
      "3\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:53:39\n",
      "loop start time 20200624 07:53:39\n",
      "4\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:53:48\n",
      "loop start time 20200624 07:53:48\n",
      "5\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:53:56\n",
      "loop start time 20200624 07:53:56\n",
      "6\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:54:04\n",
      "loop start time 20200624 07:54:04\n",
      "7\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:54:10\n",
      "loop start time 20200624 07:54:10\n",
      "8\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:54:18\n",
      "loop start time 20200624 07:54:18\n",
      "9\n",
      "using cali holiday calendar\n",
      "loop end time 20200624 07:54:25\n"
     ]
    }
   ],
   "source": [
    "for index,i in df_item_id.iterrows():\n",
    "    if index >= 0 and index < 100:\n",
    "        print(F\"loop start time {datetime.strftime(datetime.now(),format='%Y%m%d %H:%M:%S')}\")\n",
    "        print(i['item_sk'])\n",
    "        df_item_sk_1 = df_read_full_file[(df_read_full_file.item_sk == i['item_sk'])]\n",
    "        df_item_sk_1[['unwanted','date_sk2']] = df_item_sk_1.date.str.split(\"_\",expand=True)\n",
    "        df_item_sk_1.drop(columns=['unwanted','date'],inplace=True)\n",
    "        df_item_sk_1.rename(columns={'date_sk2':'date_sk'},inplace=True)\n",
    "        df_item_sk_1.date_sk = df_item_sk_1.date_sk.astype('int64')\n",
    "        df_item_sk_1 = df_item_sk_1.join(df_calendar.set_index('date_sk'),on=['date_sk'],rsuffix='xxx')\n",
    "        df1_for_fb = df_item_sk_1[['date','unit_sold']]\n",
    "        df1_for_fb.rename(columns={'date':'ds','unit_sold':'y'},inplace=True)\n",
    "        if i['state_id'] == 'CA':\n",
    "            m = fb.Prophet(holidays=holiday_ca,daily_seasonality=True)\n",
    "            print(\"using cali holiday calendar\")\n",
    "        elif i['state_id'] == 'TX':\n",
    "            m = fb.Prophet(holidays=holiday_tx,daily_seasonality=True)\n",
    "            print(\"using texas holiday calendar\")\n",
    "        else:\n",
    "            m = fb.Prophet(holidays=holiday_wi,daily_seasonality=True)\n",
    "            print(\"using wisconsin holiday calendar\")\n",
    "        m.fit(df1_for_fb)\n",
    "        future = m.make_future_dataframe(periods=28)\n",
    "        forecast = m.predict(future)\n",
    "        forecast = forecast[['ds','yhat']][forecast.ds > df1_for_fb.ds.max()]\n",
    "        df_calendar.set_index(['date'],inplace=True)\n",
    "        forecast['date_key'] = forecast.ds.apply(lambda x: calendar_lookup(x))\n",
    "        forecast = forecast[['date_key','yhat']]\n",
    "        forecast.set_index(['date_key'],inplace=True)\n",
    "        forecast = forecast.transpose()\n",
    "        forecast = forecast.iloc[:,-28:]\n",
    "        forecast.insert(0,'item_sk',i['item_sk'])\n",
    "        #forecast.insert(1,'store_sk',i['store_sk'])\n",
    "        df_calendar.reset_index(inplace=True)\n",
    "        forecast.to_csv(file_path + 'walmart_prediction5.csv', index=False, header=False, mode='a')\n",
    "        print(F\"loop end time {datetime.strftime(datetime.now(),format='%Y%m%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>unit_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id state_id date  unit_sold\n",
       "0  HOBBIES_1_001_CA_1_validation       CA  d_1          0\n",
       "1  HOBBIES_1_001_CA_1_validation       CA  d_2          0\n",
       "2  HOBBIES_1_001_CA_1_validation       CA  d_3          0\n",
       "3  HOBBIES_1_001_CA_1_validation       CA  d_4          0\n",
       "4  HOBBIES_1_001_CA_1_validation       CA  d_5          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_full_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 id    HOBBIES_1_001_CA_1_validation\n",
      "Name: 0, dtype: object\n",
      "1913 id    HOBBIES_1_002_CA_1_validation\n",
      "Name: 1913, dtype: object\n",
      "3826 id    HOBBIES_1_003_CA_1_validation\n",
      "Name: 3826, dtype: object\n",
      "5739 id    HOBBIES_1_004_CA_1_validation\n",
      "Name: 5739, dtype: object\n",
      "7652 id    HOBBIES_1_005_CA_1_validation\n",
      "Name: 7652, dtype: object\n",
      "9565 id    HOBBIES_1_006_CA_1_validation\n",
      "Name: 9565, dtype: object\n",
      "11478 id    HOBBIES_1_007_CA_1_validation\n",
      "Name: 11478, dtype: object\n",
      "13391 id    HOBBIES_1_008_CA_1_validation\n",
      "Name: 13391, dtype: object\n",
      "15304 id    HOBBIES_1_009_CA_1_validation\n",
      "Name: 15304, dtype: object\n",
      "17217 id    HOBBIES_1_010_CA_1_validation\n",
      "Name: 17217, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index,i in df_item_id.iterrows():\n",
    "    print(index,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id state_id\n",
       "0     HOBBIES_1_001_CA_1_validation       CA\n",
       "1913  HOBBIES_1_002_CA_1_validation       CA\n",
       "3826  HOBBIES_1_003_CA_1_validation       CA\n",
       "5739  HOBBIES_1_004_CA_1_validation       CA\n",
       "7652  HOBBIES_1_005_CA_1_validation       CA"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>HOBBIES_1_006_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11478</th>\n",
       "      <td>HOBBIES_1_007_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15304</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17217</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id state_id\n",
       "0      HOBBIES_1_001_CA_1_validation       CA\n",
       "1913   HOBBIES_1_002_CA_1_validation       CA\n",
       "3826   HOBBIES_1_003_CA_1_validation       CA\n",
       "5739   HOBBIES_1_004_CA_1_validation       CA\n",
       "7652   HOBBIES_1_005_CA_1_validation       CA\n",
       "9565   HOBBIES_1_006_CA_1_validation       CA\n",
       "11478  HOBBIES_1_007_CA_1_validation       CA\n",
       "13391  HOBBIES_1_008_CA_1_validation       CA\n",
       "15304  HOBBIES_1_009_CA_1_validation       CA\n",
       "17217  HOBBIES_1_010_CA_1_validation       CA"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop start time 20200623 07:45:14\n",
      "0 HOBBIES_1_001_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "1 HOBBIES_1_002_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "2 HOBBIES_1_003_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "3 HOBBIES_1_004_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "4 HOBBIES_1_005_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "5 HOBBIES_1_006_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "6 HOBBIES_1_007_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "7 HOBBIES_1_008_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "8 HOBBIES_1_009_CA_1_validation\n",
      "loop start time 20200623 07:45:14\n",
      "9 HOBBIES_1_010_CA_1_validation\n"
     ]
    }
   ],
   "source": [
    "for index,i in df_item_id.iterrows():\n",
    "    #if index >= 0 and index < 100:\n",
    "        print(F\"loop start time {datetime.strftime(datetime.now(),format='%Y%m%d %H:%M:%S')}\")\n",
    "        print(index,i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = ['id','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22','F23','F24','F25','F26','F27','F28']\n",
    "file_write = open(file_path + 'walmart_prediction7.csv','w',newline='')\n",
    "row_write = csv.writer(file_write)\n",
    "\n",
    "row_write.writerow(row1)\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
